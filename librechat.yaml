# LibreChat Configuration - Simplified Setup
# Combined Memory - LibreChat ðŸª¶ Production Configuration
# Version: 1.2.8

version: 1.2.8

# Cache settings
cache: true

# File storage configuration
fileStrategy: "local"

# Custom interface configuration
interface:
  customWelcome: 'Welcome to Combined Memory - LibreChat! ðŸ§  Your AI chat platform with integrated memory, n8n workflows, and development tools.'
  fileSearch: true
  endpointsMenu: true
  modelSelect: true
  parameters: true
  sidePanel: true
  presets: true
  prompts: true
  bookmarks: true
  multiConvo: true
  agents: true
  # Mobile optimization settings
  mobileOptimized: true
  lazyLoading: false
  peoplePicker:
    users: true
    groups: true
    roles: true
  marketplace:
    use: false
  fileCitations: true

# Registration configuration
registration:
  socialLogins: ['github', 'google', 'discord']

# Actions configuration
actions:
  allowedDomains:
    - 'api.github.com'
    - 'librechat.ai'
    - 'railway.app'
    - 'webflow.com'
    - 'notion.so'
    - 'firecrawl.dev'
    - 'up.railway.app'
    - 'combinedmemory.com'
    - 'maymarketingseo.com'
    - 'google.serper.dev'
    - 'jina.ai'
    - 'mcp.jina.ai'
    - 'res.cloudinary.com'
    - 'railway.app'
    - 'webflow.com'
    - 'n8n.io'
    - 'jina.ai'
    - 'notion.so'
    - 'upstash.com'
    - 'github.com'
    - 'steel-browser.com'
    - 'api-production-98ab.up.railway.app'
    - 'ui-production-b17b.up.railway.app'

# MCP Servers Configuration - Essential Only
mcpServers:
  # Development & Project Management
  railway:
    type: stdio
    command: npx
    args:
      - '@jasontanswe/railway-mcp'
    env:
      RAILWAY_TOKEN: 'ce075fe8-1873-4d61-a67a-f65a698ae3ec'
    timeout: 60000
    iconPath: https://railway.app/favicon.ico

  # Web Development & Design (Local API Token)
  webflow:
    type: stdio
    command: npx
    args:
      - '-y'
      - 'webflow-mcp-server'
    env:
      WEBFLOW_TOKEN: '${WEBFLOW_TOKEN}'
    timeout: 60000
    iconPath: https://webflow.com/favicon.ico

  # Workflow Automation
  n8n-railway:
    type: stdio
    command: npx
    args:
      - '-y'
      - 'mcp-remote'
      - 'https://czlonkowskin8n-mcp-railwaylatest-production-23d6.up.railway.app/mcp'
      - '--header'
      - 'Authorization: Bearer cwmWLcSwK2jIuwCAgtYeDDwztEkc1afLomiFszDd8Fc='
    timeout: 60000
    iconPath: https://n8n.io/favicon.ico

  # Memory & AI Enhancement
  quinns-memory:
    type: http
    url: https://server.smithery.ai/@quinnbmay/quinns-memory-mcp-server/mcp?api_key=${QUINNS_MEMORY_API_KEY}&profile=${QUINNS_MEMORY_PROFILE}
    timeout: 60000
    iconPath: https://res.cloudinary.com/dfctldgya/image/upload/v1757455636/uewnvovkzpr46dyfaia3.png

  # Document Processing & AI Analysis
  jina-mcp-server:
    type: stdio
    command: npx
    args:
      - '-y'
      - 'mcp-remote'
      - 'https://mcp.jina.ai/sse'
      - '--header'
      - 'Authorization: Bearer ${JINA_API_KEY}'
    timeout: 60000
    iconPath: https://jina.ai/favicon.ico

  # Notion - Database & Page Management (Smithery-hosted)
  notion-mcp:
    type: http
    url: https://server.smithery.ai/@smithery/notion/mcp?api_key=c0696122-7da9-4c99-84e2-1798ce74a954&profile=given-narwhal-PvFXc4
    timeout: 60000
    iconPath: https://notion.so/images/favicon.ico

  # Upstash Context7 - Documentation & Code Examples (Smithery-hosted)
  upstash-context7:
    type: http
    url: https://server.smithery.ai/@upstash/context7-mcp/mcp?api_key=c0696122-7da9-4c99-84e2-1798ce74a954&profile=given-narwhal-PvFXc4
    timeout: 60000
    iconPath: https://upstash.com/favicon.ico

  # GitHub - Repository Management & Copilot Integration (Smithery-hosted)
  github:
    type: http
    url: https://server.smithery.ai/@smithery-ai/github/mcp?api_key=c0696122-7da9-4c99-84e2-1798ce74a954&profile=given-narwhal-PvFXc4
    timeout: 60000
    iconPath: https://github.com/favicon.ico

# Steel Browser - Removed due to package not found error


# Endpoints configuration - OpenRouter + Agents
endpoints:
  # AI Agents Configuration
  agents:
    recursionLimit: 50
    maxRecursionLimit: 100
    disableBuilder: false
    capabilities: ["execute_code", "file_search", "actions", "tools", "artifacts", "ocr", "chain", "web_search"]
    maxCitations: 30
    maxCitationsPerFile: 7
    minRelevanceScore: 0.45

  # OpenAI Direct Integration - Latest Models
  openAI:
    apiKey: '${OPENAI_API_KEY}'
    organizationId: '${OPENAI_ORG_ID}'
    models:
      default: 
        # GPT-4 Family - Production Models
        - "gpt-4o"
        - "gpt-4o-mini"
        - "gpt-4-turbo"
        - "gpt-4"
        - "gpt-3.5-turbo"
    titleConvo: true
    titleModel: "gpt-3.5-turbo"
    summarize: false
    summaryModel: "gpt-3.5-turbo"
    forcePrompt: false
    modelDisplayLabel: "OpenAI"

  custom:
    # Mistral Direct API - Native Mistral Models
    - name: "Mistral"
      apiKey: "${MISTRAL_API_KEY}"
      baseURL: "https://api.mistral.ai/v1"
      models:
        default: ["mistral-tiny", "mistral-small", "mistral-medium", "mistral-large-latest"]
        fetch: true
      titleConvo: true
      titleModel: "mistral-tiny"
      modelDisplayLabel: "Mistral"
      dropParams: ["stop", "user", "frequency_penalty", "presence_penalty"]

    # Google Gemini Direct API - Native Google Models
    - name: "Google"
      apiKey: "${GOOGLE_API_KEY}"
      baseURL: "https://generativelanguage.googleapis.com/v1beta"
      models:
        default: 
          - "gemini-2.0-flash-exp"
          - "gemini-1.5-pro-latest"
          - "gemini-1.5-flash"
          - "gemini-1.5-flash-8b"
          - "gemini-pro"
        fetch: true
      titleConvo: true
      titleModel: "gemini-1.5-flash"
      modelDisplayLabel: "Google Gemini"
      dropParams: ["stop", "logit_bias", "user"]

# File configuration
fileConfig:
  endpoints:
    assistants:
      fileLimit: 10
      fileSizeLimit: 50
      totalSizeLimit: 200
      supportedMimeTypes:
        - "image/.*"
        - "application/pdf"
        - "text/.*"
        - "application/vnd.openxmlformats-officedocument.*"
    openAI:
      fileLimit: 10
      fileSizeLimit: 50
      totalSizeLimit: 200
      supportedMimeTypes:
        - "image/.*"
        - "application/pdf"
        - "text/.*"
        - "application/vnd.openxmlformats-officedocument.*"
    custom:
      fileLimit: 10
      fileSizeLimit: 50
      totalSizeLimit: 200
      supportedMimeTypes:
        - "image/.*"
        - "application/pdf"
        - "text/.*"
        - "application/vnd.openxmlformats-officedocument.*"
    default:
      fileLimit: 10
      fileSizeLimit: 50
      totalSizeLimit: 200
      supportedMimeTypes:
        - "image/.*"
        - "application/pdf"
        - "text/.*"
        - "application/vnd.openxmlformats-officedocument.*"
  serverFileSizeLimit: 500
  avatarSizeLimit: 5

# Note: Code Interpreter is configured via environment variables
# LIBRECHAT_CODE_API_KEY is set in Railway environment

# Speech configuration - ElevenLabs TTS + OpenAI Whisper STT Integration
speech:
  # Speech Tab - Enhanced User Controls & Default Settings
  speechTab:
    conversationMode: true
    advancedMode: true
    speechToText:
      engineSTT: "external"
      languageSTT: "English (US)"
      autoTranscribeAudio: true
      decibelValue: -45
      autoSendText: 0
    textToSpeech:
      engineTTS: "external"
      voice: "Rachel"
      languageTTS: "en"
      automaticPlayback: true
      playbackRate: 1.0
      cacheTTS: true
  
  # Speech-to-Text (STT) - OpenAI Whisper
  stt:
    openai:
      apiKey: '${OPENAI_API_KEY}'
      model: 'whisper-1'
  
  # Text-to-Speech (TTS) - ElevenLabs
  tts:
    elevenlabs:
      apiKey: '${TTS_API_KEY}'
      model: 'eleven_multilingual_v2'
      voices: ['Rachel']
      voice_settings:
        similarity_boost: 0.75
        stability: 0.50
        style: 0.0
        use_speaker_boost: true

# Balance API configuration for usage monitoring
balance:
  enabled: false
  providers:
    openai:
      apiKey: '${OPENAI_API_KEY}'
    mistral:
      apiKey: '${MISTRAL_API_KEY}'
    google:
      apiKey: '${GOOGLE_API_KEY}'
    elevenlabs:
      apiKey: '${TTS_API_KEY}'

# Memory configuration for user context
memory:
  disabled: false
  validKeys: ["preferences", "work_info", "personal_info", "skills", "interests", "context", "projects", "mcp_configs"]
  tokenLimit: 15000
  personalize: true
  agent:
    provider: "OpenAI"
    model: "gpt-4o-mini"
    instructions: "You are Quinn's memory management assistant. Store and organize user information, project context, MCP server configurations, and development preferences accurately with timestamps."
    model_parameters:
      temperature: 0.1