# LibreChat Configuration - Simplified Setup
# Combined Memory - LibreChat ðŸª¶ Production Configuration
# Version: 1.2.8

version: 1.2.8

# Cache settings
cache: true

# File storage configuration
fileStrategy: "local"

# Custom interface configuration
interface:
  customWelcome: 'Welcome to Combined Memory - LibreChat! Your AI chat platform with integrated memory, n8n workflows, and development tools.'
  fileSearch: true
  endpointsMenu: true
  modelSelect: true
  parameters: true
  sidePanel: true
  presets: true
  prompts: true
  bookmarks: true
  multiConvo: true
  agents: true
  peoplePicker:
    users: true
    groups: true
    roles: true
  marketplace:
    use: false
  fileCitations: true

# Registration configuration
registration:
  socialLogins: ['github', 'google', 'discord']

# Actions configuration
actions:
  allowedDomains:
    - 'api.github.com'
    - 'librechat.ai'
    - 'railway.app'
    - 'webflow.com'
    - 'notion.so'
    - 'firecrawl.dev'
    - 'up.railway.app'
    - 'combinedmemory.com'
    - 'maymarketingseo.com'

# MCP Servers Configuration - Essential Only
mcpServers:
  # Development & Project Management
  railway:
    type: stdio
    command: npx
    args:
      - '@jasontanswe/railway-mcp'
    timeout: 60000
    iconPath: /railway-icon.svg

  # Web Development & Design
  webflow:
    type: stdio
    command: npx
    args:
      - '-y'
      - 'webflow-mcp-server@0.6.0'
    timeout: 60000
    iconPath: /webflow-icon.svg

  # Workflow Automation
  n8n-railway:
    type: stdio
    command: npx
    args:
      - '-y'
      - 'mcp-remote'
      - 'https://czlonkowskin8n-mcp-railwaylatest-production-23d6.up.railway.app/mcp'
      - '--header'
      - 'Authorization: Bearer cwmWLcSwK2jIuwCAgtYeDDwztEkc1afLomiFszDd8Fc='
    timeout: 60000
    iconPath: /n8n-icon.svg

  # Memory & AI Enhancement
  quinns-memory:
    type: http
    url: https://server.smithery.ai/@quinnbmay/quinns-memory-mcp-server/mcp?api_key=${QUINNS_MEMORY_API_KEY}&profile=${QUINNS_MEMORY_PROFILE}
    timeout: 60000
    iconPath: /memory-icon.svg

# Endpoints configuration - OpenRouter Only
endpoints:
  custom:
    # OpenRouter - Primary flagship models
    - name: 'OpenRouter'
      apiKey: '${OPENROUTER_KEY}'
      baseURL: 'https://openrouter.ai/api/v1'
      models:
        default: 
          # Your Custom Preset & Auto
          - '@preset/ai-stack'
          - 'openrouter/auto'
          
          # Latest & Greatest (2025)
          - 'qwen/qwen3-max'
          - 'deepseek/deepseek-chat-v3.1'
          - 'deepseek/deepseek-v3.1-base'
          - 'anthropic/claude-opus-4.1'
          - 'openai/gpt-5-chat'
          - 'openai/gpt-5'
          - 'openai/gpt-5-mini'
          - 'openai/gpt-5-nano'
          - 'mistralai/mistral-medium-3.1'
          - 'mistralai/codestral-2508'
          - 'x-ai/grok-code-fast-1'
          - 'nousresearch/hermes-4-70b'
          - 'nousresearch/hermes-4-405b'
          
          # OpenAI Models
          - 'openai/gpt-4o'
          - 'openai/gpt-4o-mini'
          - 'openai/gpt-4o-audio-preview'
          - 'openai/o1-preview'
          - 'openai/o1-mini'
          - 'openai/gpt-4-turbo'
          - 'openai/gpt-4'
          - 'openai/gpt-3.5-turbo'
          - 'openai/gpt-oss-120b'
          - 'openai/gpt-oss-20b'
          
          # Anthropic Claude
          - 'anthropic/claude-3.5-sonnet'
          - 'anthropic/claude-3.5-haiku'
          - 'anthropic/claude-3-opus'
          - 'anthropic/claude-3-sonnet'
          - 'anthropic/claude-3-haiku'
          
          # Google Gemini
          - 'google/gemini-2.5-flash-image-preview'
          - 'google/gemini-2.0-flash-exp'
          - 'google/gemini-1.5-pro'
          - 'google/gemini-1.5-flash'
          - 'google/gemini-1.5-flash-8b'
          
          # Meta LLaMA
          - 'meta-llama/llama-3.3-70b-instruct'
          - 'meta-llama/llama-3.1-405b-instruct'
          - 'meta-llama/llama-3.1-70b-instruct'
          - 'meta-llama/llama-3.1-8b-instruct'
          - 'meta-llama/llama-3.2-90b-vision-instruct'
          - 'meta-llama/llama-3.2-11b-vision-instruct'
          - 'meta-llama/llama-3.2-3b-instruct'
          - 'meta-llama/llama-3.2-1b-instruct'
          
          # Mistral AI
          - 'mistralai/mistral-large-2411'
          - 'mistralai/mistral-medium'
          - 'mistralai/mistral-small'
          - 'mistralai/codestral-latest'
          - 'mistralai/pixtral-large-latest'
          - 'mistralai/pixtral-12b'
          
          # DeepSeek
          - 'deepseek/deepseek-chat'
          - 'deepseek/deepseek-coder'
          - 'deepseek/deepseek-r1'
          - 'deepseek/deepseek-reasoner'
          
          # Qwen (Alibaba)
          - 'qwen/qwen-2.5-72b-instruct'
          - 'qwen/qwen-2.5-32b-instruct'
          - 'qwen/qwen-2.5-14b-instruct'
          - 'qwen/qwen-2.5-7b-instruct'
          - 'qwen/qwen3-30b-a3b-instruct'
          - 'qwen/qwen3-coder-30b-a3b-instruct'
          
          # xAI Grok
          - 'x-ai/grok-2-1212'
          - 'x-ai/grok-2-vision-1212'
          - 'x-ai/grok-beta'
          
          # Cohere
          - 'cohere/command-r-plus'
          - 'cohere/command-r'
          - 'cohere/command-r-plus-08-2024'
          
          # AI21 Jamba
          - 'ai21/jamba-large-1.7'
          - 'ai21/jamba-mini-1.7'
          - 'ai21/jamba-instruct'
          
          # Perplexity (Online Models)
          - 'perplexity/llama-3.1-sonar-large-128k-online'
          - 'perplexity/llama-3.1-sonar-small-128k-online'
          - 'perplexity/llama-3.1-sonar-large-128k-chat'
          - 'perplexity/llama-3.1-sonar-small-128k-chat'
          
          # Specialized Models
          - 'z-ai/glm-4.5v'
          - 'baidu/ernie-4.5-21b-a3b'
          - 'baidu/ernie-4.5-vl-28b-a3b'
          - 'moonshotai/kimi-k2-0905'
          
          # Free Models
          - 'deepseek/deepseek-chat-v3.1:free'
          - 'openai/gpt-oss-120b:free'
          - 'openai/gpt-oss-20b:free'
          - 'meta-llama/llama-3.1-8b-instruct:free'
          - 'meta-llama/llama-3.2-3b-instruct:free'
          - 'meta-llama/llama-3.2-1b-instruct:free'
          
        fetch: false
      titleConvo: true
      titleModel: 'meta-llama/llama-3.3-70b-instruct'
      dropParams: ['stop']
      modelDisplayLabel: 'OpenRouter'

# File configuration
fileConfig:
  endpoints:
    assistants:
      fileLimit: 10
      fileSizeLimit: 50
      totalSizeLimit: 200
      supportedMimeTypes:
        - "image/.*"
        - "application/pdf"
        - "text/.*"
        - "application/vnd.openxmlformats-officedocument.*"
    default:
      totalSizeLimit: 100
  serverFileSizeLimit: 500
  avatarSizeLimit: 5

# Code Interpreter configuration
codeInterpreter:
  enabled: true
  apiKey: '${LIBRECHAT_CODE_API_KEY}'
  baseURL: 'https://api.librechat.ai/v1'
  timeout: 30000
  supportedLanguages:
    - 'python'
    - 'javascript' 
    - 'typescript'
    - 'go'
    - 'java'
    - 'cpp'
    - 'rust'
    - 'r'

# Memory configuration for user context
memory:
  disabled: false
  validKeys: ["preferences", "work_info", "personal_info", "skills", "interests", "context", "projects", "mcp_configs"]
  tokenLimit: 15000
  personalize: true
  agent:
    provider: "OpenRouter"
    model: "openai/gpt-4o-mini"
    instructions: "You are Quinn's memory management assistant. Store and organize user information, project context, MCP server configurations, and development preferences accurately with timestamps."
    model_parameters:
      temperature: 0.1